
# åˆ†å¡Šä¸Šå‚³çš„è³‡æ–™åº«æ¨¡å‹è¨­è¨ˆ

èšç„¦åœ¨è³‡æ–™åº«å±¤é¢ï¼Œåˆ†æå¦‚ä½•ä¿®æ”¹ç¾æœ‰çš„ [`models.py`](filemanageportal/backend/src/models.py:1) ä¾†æ”¯æ´åˆ†å¡Šä¸Šå‚³èˆ‡æ–·é»çºŒå‚³ã€‚

## ğŸ¯ æ ¸å¿ƒå•é¡Œåˆ†æ

### **æ˜¯å¦éœ€è¦ä½¿ç”¨ Blob Storage ç‰¹æ€§ï¼Ÿ**

**ç­”æ¡ˆï¼šä¸ä¸€å®šéœ€è¦ï¼Œä½†å¯ä»¥åˆ©ç”¨ã€‚**

æ ¹æ“šç¾æœ‰çš„ [`StorageService`](filemanageportal/backend/src/storage.py:19) æ¶æ§‹ï¼Œç³»çµ±æ”¯æ´å…©ç¨®å„²å­˜æ¨¡å¼ï¼š

1. **Local Storage** - ä¸éœ€è¦ Blob Storage ç‰¹æ€§
2. **Supabase Storage** - å¯ä»¥åˆ©ç”¨ Blob Storage çš„ Multipart Upload ç‰¹æ€§

---

## ğŸ“Š è³‡æ–™åº«æ¨¡å‹è¨­è¨ˆæ–¹æ¡ˆ

### **æ–¹æ¡ˆ Aï¼šç´”è³‡æ–™åº«è¿½è¹¤ï¼ˆæ¨è–¦ç”¨æ–¼ Local Storageï¼‰**

æ–°å¢ `ChunkedUpload` æ¨¡å‹åˆ° [`models.py`](filemanageportal/backend/src/models.py:1)ï¼š

```python
class ChunkedUpload(db.Model):
    """
    è¿½è¹¤åˆ†å¡Šä¸Šå‚³çš„ç‹€æ…‹
    é©ç”¨æ–¼ Local Storage å’Œ Supabase Storage
    """
    
    __tablename__ = 'chunked_uploads'
    
    # === ä¸»éµèˆ‡é—œè¯ ===
    id = db.Column(db.String(36), primary_key=True)  # UUID
    user_id = db.Column(db.Integer, db.ForeignKey('users.id'), nullable=False, index=True)
    user = db.relationship('User', backref='chunked_uploads')
    
    # === æª”æ¡ˆåŸºæœ¬è³‡è¨Š ===
    filename = db.Column(db.String(255), nullable=False)
    original_filename = db.Column(db.String(255), nullable=False)
    file_size = db.Column(db.BigInteger, nullable=False)  # ç¸½å¤§å°ï¼ˆbytesï¼‰
    mime_type = db.Column(db.String(100), nullable=True)
    file_hash = db.Column(db.String(64), nullable=True)  # ç”¨æ–¼å»é‡
    
    # === åˆ†å¡Šé…ç½® ===
    chunk_size = db.Column(db.Integer, nullable=False, default=5242880)  # 5MB
    total_chunks = db.Column(db.Integer, nullable=False)
    
    # === ä¸Šå‚³é€²åº¦è¿½è¹¤ï¼ˆæ ¸å¿ƒæ¬„ä½ï¼‰===
    uploaded_chunks = db.Column(db.JSON, nullable=False, default=list)
    # æ ¼å¼: [0, 1, 2, 5, 7] - å·²ä¸Šå‚³çš„å¡Šç´¢å¼•
    # æˆ–æ›´è©³ç´°: [{"index": 0, "hash": "abc123", "size": 5242880}, ...]
    
    # === ç‹€æ…‹ç®¡ç† ===
    status = db.Column(
        db.String(20), 
        nullable=False, 
        default='pending',
        index=True
    )
    # ç‹€æ…‹å€¼:
    # - pending: å·²åˆå§‹åŒ–ï¼Œå°šæœªé–‹å§‹ä¸Šå‚³
    # - uploading: ä¸Šå‚³ä¸­
    # - merging: æ­£åœ¨åˆä½µåˆ†å¡Š
    # - completed: å·²å®Œæˆ
    # - failed: å¤±æ•—
    # - expired: å·²éæœŸ
    
    # === å„²å­˜è·¯å¾‘ ===
    temp_dir = db.Column(db.String(512), nullable=False)
    # Local: "uploads/temp/user_123/upload_uuid/"
    # Supabase: "temp/user_123/upload_uuid/"
    
    storage_path = db.Column(db.String(512), nullable=True)
    # å®Œæˆå¾Œçš„æœ€çµ‚è·¯å¾‘ï¼Œå°æ‡‰åˆ° File.file_path
    
    storage_mode = db.Column(db.String(20), nullable=False)
    # "local" æˆ– "supabase"
    
    # === æ™‚é–“æˆ³è¨˜ ===
    created_at = db.Column(db.DateTime, nullable=False, default=datetime.utcnow, index=True)
    updated_at = db.Column(db.DateTime, nullable=False, default=datetime.utcnow, onupdate=datetime.utcnow)
    expires_at = db.Column(db.DateTime, nullable=False, index=True)
    # é è¨­ 24 å°æ™‚å¾ŒéæœŸ: created_at + timedelta(hours=24)
    
    completed_at = db.Column(db.DateTime, nullable=True)
    
    # === é—œè¯åˆ°æœ€çµ‚æª”æ¡ˆ ===
    file_id = db.Column(db.Integer, db.ForeignKey('files.id'), nullable=True)
    # å®Œæˆå¾ŒæŒ‡å‘å»ºç«‹çš„ File è¨˜éŒ„
    
    # === è¼”åŠ©æ–¹æ³• ===
    
    def get_progress_percentage(self) -> float:
        """è¨ˆç®—ä¸Šå‚³é€²åº¦ç™¾åˆ†æ¯”"""
        if self.total_chunks == 0:
            return 0.0
        return (len(self.uploaded_chunks) / self.total_chunks) * 100
    
    def get_uploaded_size(self) -> int:
        """è¨ˆç®—å·²ä¸Šå‚³çš„å¤§å°ï¼ˆbytesï¼‰"""
        return len(self.uploaded_chunks) * self.chunk_size
    
    def is_complete(self) -> bool:
        """æª¢æŸ¥æ˜¯å¦æ‰€æœ‰å¡Šéƒ½å·²ä¸Šå‚³"""
        return len(self.uploaded_chunks) == self.total_chunks
    
    def is_expired(self) -> bool:
        """æª¢æŸ¥æ˜¯å¦å·²éæœŸ"""
        return datetime.utcnow() > self.expires_at
    
    def get_missing_chunks(self) -> list:
        """å–å¾—å°šæœªä¸Šå‚³çš„å¡Šç´¢å¼•"""
        all_chunks = set(range(self.total_chunks))
        uploaded = set(self.uploaded_chunks)
        return sorted(list(all_chunks - uploaded))
    
    def mark_chunk_uploaded(self, chunk_index: int) -> None:
        """æ¨™è¨˜æŸå€‹å¡Šå·²ä¸Šå‚³ï¼ˆå†ªç­‰æ“ä½œï¼‰"""
        if chunk_index not in self.uploaded_chunks:
            self.uploaded_chunks.append(chunk_index)
            self.uploaded_chunks.sort()
            
            if self.status == 'pending':
                self.status = 'uploading'
            
            self.updated_at = datetime.utcnow()
            
            # ä½¿ç”¨ flag_modified ç¢ºä¿ JSON æ¬„ä½æ›´æ–°
            from sqlalchemy.orm.attributes import flag_modified
            flag_modified(self, 'uploaded_chunks')
    
    def to_dict(self) -> dict:
        """è½‰æ›ç‚ºå­—å…¸"""
        return {
            'id': self.id,
            'user_id': self.user_id,
            'filename': self.original_filename,
            'file_size': self.file_size,
            'mime_type': self.mime_type,
            'chunk_size': self.chunk_size,
            'total_chunks': self.total_chunks,
            'uploaded_chunks': self.uploaded_chunks,
            'missing_chunks': self.get_missing_chunks(),
            'status': self.status,
            'progress': self.get_progress_percentage(),
            'uploaded_size': self.get_uploaded_size(),
            'storage_mode': self.storage_mode,
            'created_at': self.created_at.isoformat(),
            'updated_at': self.updated_at.isoformat(),
            'expires_at': self.expires_at.isoformat(),
            'completed_at': self.completed_at.isoformat() if self.completed_at else None,
        }
    
    def __repr__(self):
        return f'<ChunkedUpload {self.id} ({self.get_progress_percentage():.1f}%)>'
```

---

### **æ–¹æ¡ˆ Bï¼šåˆ©ç”¨ Supabase Multipart Uploadï¼ˆé€²éšï¼‰**

å¦‚æœä½¿ç”¨ Supabase Storageï¼Œå¯ä»¥åˆ©ç”¨å…¶åŸç”Ÿçš„ Multipart Upload APIï¼š

```python
class ChunkedUpload(db.Model):
    """
    è¿½è¹¤åˆ†å¡Šä¸Šå‚³çš„ç‹€æ…‹
    æ”¯æ´ Supabase Multipart Upload
    """
    
    # ... (åŸºæœ¬æ¬„ä½åŒæ–¹æ¡ˆ A)
    
    # === Supabase å°ˆç”¨æ¬„ä½ ===
    supabase_upload_id = db.Column(db.String(255), nullable=True)
    # Supabase è¿”å›çš„ multipart upload ID
    
    supabase_part_etags = db.Column(db.JSON, nullable=True, default=list)
    # æ ¼å¼: [{"PartNumber": 1, "ETag": "abc123"}, ...]
    # Supabase æ¯å€‹ part çš„ ETag
    
    def add_supabase_part(self, part_number: int, etag: str) -> None:
        """è¨˜éŒ„ Supabase part çš„ ETag"""
        if self.supabase_part_etags is None:
            self.supabase_part_etags = []
        
        self.supabase_part_etags.append({
            'PartNumber': part_number,
            'ETag': etag
        })
        
        from sqlalchemy.orm.attributes import flag_modified
        flag_modified(self, 'supabase_part_etags')
```

---

## ğŸ”‘ é—œéµè¨­è¨ˆæ±ºç­–

### **1. `uploaded_chunks` æ¬„ä½è¨­è¨ˆ**

**é¸é … Aï¼šç°¡å–®é™£åˆ—ï¼ˆæ¨è–¦ï¼‰**
```python
uploaded_chunks = db.Column(db.JSON, default=list)
# å€¼: [0, 1, 2, 5, 7]
```

**å„ªé»ï¼š**
- ç°¡å–®ç›´è§€
- æŸ¥è©¢å¿«é€Ÿï¼š`len(uploaded_chunks)` å³å¯å¾—çŸ¥é€²åº¦
- æ”¯æ´æ–·é»çºŒå‚³ï¼šç¼ºå¤±çš„å¡Š = `set(range(total)) - set(uploaded_chunks)`

**é¸é … Bï¼šè©³ç´°ç‰©ä»¶é™£åˆ—**
```python
uploaded_chunks = db.Column(db.JSON, default=list)
# å€¼: [
#   {"index": 0, "hash": "abc123", "size": 5242880, "uploaded_at": "2025-12-04T10:00:00"},
#   {"index": 1, "hash": "def456", "size": 5242880, "uploaded_at": "2025-12-04T10:00:05"}
# ]
```

**å„ªé»ï¼š**
- å¯é©—è­‰æ¯å€‹å¡Šçš„å®Œæ•´æ€§ï¼ˆhashï¼‰
- å¯è¿½è¹¤æ¯å€‹å¡Šçš„ä¸Šå‚³æ™‚é–“
- æ”¯æ´æ›´ç´°ç·»çš„éŒ¯èª¤è™•ç†

**ç¼ºé»ï¼š**
- è³‡æ–™é‡è¼ƒå¤§
- æŸ¥è©¢ç¨è¤‡é›œ

**å»ºè­°ï¼šå…ˆç”¨é¸é … Aï¼Œéœ€è¦æ™‚å†å‡ç´šåˆ°é¸é … B**

---

### **2. æ˜¯å¦éœ€è¦ Blob Storage ç‰¹æ€§ï¼Ÿ**

#### **Local Storage æ¨¡å¼ï¼š**
```
ä¸éœ€è¦ Blob Storage ç‰¹æ€§

æµç¨‹ï¼š
1. å‰ç«¯ä¸Šå‚³åˆ†å¡Š â†’ å¾Œç«¯å„²å­˜åˆ° temp_dir
2. æ‰€æœ‰å¡Šä¸Šå‚³å®Œæˆ â†’ å¾Œç«¯åˆä½µæˆå®Œæ•´æª”æ¡ˆ
3. ç§»å‹•åˆ°æœ€çµ‚ä½ç½® â†’ åˆªé™¤ temp_dir
```

**è³‡æ–™åº«åªéœ€è¿½è¹¤ï¼š**
- `uploaded_chunks`: å“ªäº›å¡Šå·²ä¸Šå‚³
- `temp_dir`: æš«å­˜ä½ç½®
- `status`: ç•¶å‰ç‹€æ…‹

---

#### **Supabase Storage æ¨¡å¼ï¼š**
```
å¯é¸æ“‡åˆ©ç”¨ Multipart Upload API

é¸é … 1ï¼šè‡ªå·±ç®¡ç†åˆ†å¡Šï¼ˆåŒ Localï¼‰
- ä¸Šå‚³åˆ° temp bucket
- åˆä½µå¾Œä¸Šå‚³åˆ° final bucket

é¸é … 2ï¼šä½¿ç”¨ Supabase Multipart Upload
- å‘¼å« createMultipartUpload()
- ä¸Šå‚³æ¯å€‹ part ä¸¦è¨˜éŒ„ ETag
- å‘¼å« completeMultipartUpload()
```

**å¦‚æœä½¿ç”¨é¸é … 2ï¼Œè³‡æ–™åº«éœ€é¡å¤–è¿½è¹¤ï¼š**
- `supabase_upload_id`: Multipart upload ID
- `supabase_part_etags`: æ¯å€‹ part çš„ ETag

**å»ºè­°ï¼š**
- åˆæœŸä½¿ç”¨é¸é … 1ï¼ˆçµ±ä¸€é‚è¼¯ï¼Œç°¡å–®ï¼‰
- éœ€è¦æ›´å¥½æ•ˆèƒ½æ™‚å‡ç´šåˆ°é¸é … 2

---

### **3. èˆ‡ç¾æœ‰ `File` æ¨¡å‹çš„é—œä¿‚**

```python
# ChunkedUpload å®Œæˆå¾Œå»ºç«‹ File è¨˜éŒ„
chunked_upload.status = 'completed'
chunked_upload.completed_at = datetime.utcnow()

# å»ºç«‹æœ€çµ‚æª”æ¡ˆè¨˜éŒ„
file = File(
    filename=chunked_upload.filename,
    original_filename=chunked_upload.original_filename,
    file_path=chunked_upload.storage_path,  # æœ€çµ‚è·¯å¾‘
    file_size=chunked_upload.file_size,
    mime_type=chunked_upload.mime_type,
    user_id=chunked_upload.user_id
)
db.session.add(file)
db.session.commit()

# é—œè¯
chunked_upload.file_id = file.id
db.session.commit()
```

**é—œä¿‚ï¼š**
- `ChunkedUpload` æ˜¯æš«æ™‚æ€§çš„ä¸Šå‚³è¿½è¹¤è¨˜éŒ„
- `File` æ˜¯æ°¸ä¹…æ€§çš„æª”æ¡ˆè¨˜éŒ„
- ä¸€å€‹ `ChunkedUpload` å®Œæˆå¾Œå°æ‡‰ä¸€å€‹ `File`

---

## ğŸ“‹ è³‡æ–™åº«é·ç§»

æ–°å¢ migrationï¼š

```python
# migrations/versions/xxx_add_chunked_upload.py

def upgrade():
    op.create_table(
        'chunked_uploads',
        sa.Column('id', sa.String(36), primary_key=True),
        sa.Column('user_id', sa.Integer, sa.ForeignKey('users.id'), nullable=False),
        sa.Column('filename', sa.String(255), nullable=False),
        sa.Column('original_filename', sa.String(255), nullable=False),
        sa.Column('file_size', sa.BigInteger, nullable=False),
        sa.Column('mime_type', sa.String(100)),
        sa.Column('chunk_size', sa.Integer, nullable=False),
        sa.Column('total_chunks', sa.Integer, nullable=False),
        sa.Column('uploaded_chunks', sa.JSON, nullable=False),
        sa.Column('status', sa.String(20), nullable=False),
        sa.Column('temp_dir', sa.String(512), nullable=False),
        sa.Column('storage_path', sa.String(512)),
        sa.Column('storage_mode', sa.String(20), nullable=False),
        sa.Column('created_at', sa.DateTime, nullable=False),
        sa.Column('updated_at', sa.DateTime, nullable=False),
        sa.Column('expires_at', sa.DateTime, nullable=False),
        sa.Column('completed_at', sa.DateTime),
        sa.Column('file_id', sa.Integer, sa.ForeignKey('files.id')),
    )
    
    # å»ºç«‹ç´¢å¼•
    op.create_index('ix_chunked_uploads_user_id', 'chunked_uploads', ['user_id'])
    op.create_index('ix_chunked_uploads_status', 'chunked_uploads', ['status'])